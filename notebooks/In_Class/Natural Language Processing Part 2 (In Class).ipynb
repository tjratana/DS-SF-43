{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing (NLP) Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time to pick up where we left off\n",
    "\n",
    "**Goals:**\n",
    "\n",
    "- Finish text classification lesson by using stemming and lemmatization in our vectorizers\n",
    "- Build a simple text summarizer\n",
    "- How to find similar documents with cosine similarity and clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "from time import time\n",
    "import pandas as pd\n",
    "pd.set_option(\"max.colwidth\", 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sb\n",
    "from sklearn.cross_validation import train_test_split, cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import PCA, TruncatedSVD, NMF\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, wordpunct_tokenize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tag import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification continued"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To wrap our text classification section, we're going to learn how to incorporate stemming and lemmatization in our vectorizers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in yelp review data\n",
    "\n",
    "path = \"../../data/NLP_data/yelp.csv\"\n",
    "\n",
    "yelp = pd.read_csv(path, encoding='unicode-escape')\n",
    "\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame called yelp_best_worst that only contains the 5-star and 1-star reviews\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars\n",
    "\n",
    "#Null accuracy\n",
    "print y.value_counts(normalize=True)\n",
    "\n",
    "# split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Look at the analyzer section of the CountVectorizer doc strings\n",
    "CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analyzer argument allows us to upload our function to transform/tokenize the words in our corpura"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that accepts text and returns a list of stems\n",
    "def word_tokenize_stem(text):\n",
    "    #Transform and tokenize words using TextBlob\n",
    "    \n",
    "    #Intialize stemmer\n",
    "    \n",
    "    #Return a list of the stems\n",
    "    \n",
    "\n",
    "\n",
    "# define a function that accepts text and returns a list of lemons (noun version)\n",
    "def word_tokenize_lemma(text):\n",
    "    #Transform and tokenize words using TextBlob\n",
    "    \n",
    "    #Return a list of lemons\n",
    "    \n",
    "\n",
    "# define a function that accepts text and returns a list of lemons (verb version)\n",
    "def word_tokenize_lemma_verb(text):\n",
    "    \n",
    "    #Return a list of lemons    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try our three new functions with both count and tfidf vectorizers. \n",
    "<br>\n",
    "- First let's create a function that takes in an initialized but unfit vectorizer as an argument.\n",
    "- Fit and transforms training data using the vectorizer\n",
    "- Transforms the testing data\n",
    "- Fits naive bayes model on training data.\n",
    "- Evaluate it on the training and testing data.\n",
    "- Prints the number of features and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_model_evaluator(vect):\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"Features: \", )\n",
    "    print (\"Training Score: \", )\n",
    "    print (\"Testing Score: \", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Count Vectorizer with stop_words set to english and analyzer to word_tokenize_stem\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Count Vectorizer with stop_words set to english and analyzer to word_tokenize_lemma\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Count Vectorizer with stop_words set to english and analyzer to word_tokenize_lemma_verb\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do you interpret these results? Let's try it again with tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Tfidf Vectorizer with stop_words set to english and analyzer to word_tokenize_stem\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Tfidf Vectorizer with stop_words set to english and analyzer to word_tokenize_lemma\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize Tfidf Vectorizer with stop_words set to english and analyzer to word_tokenize_lemma\n",
    "\n",
    "vect = \n",
    "\n",
    "#Pass vectorizer into function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the tfidf vectorizers compare to counts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search time. Let's grid search objects that incorporate all of the analyzer functions for count and tfidf vectorizers. In addition we'll do the same for randomized search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipeline for countvectorizer and naive bayes model\n",
    "pipe_cv = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "#Intialize parameters for count vectorizer\n",
    "param_grid_cv = {}\n",
    "param_grid_cv[\"countvectorizer__max_features\"] = [1000, 2500 ,5000, 7500,10000]\n",
    "param_grid_cv[\"countvectorizer__ngram_range\"] = [(1,1), (1,2), (2,2)]\n",
    "param_grid_cv[\"countvectorizer__lowercase\"] = [True, False]\n",
    "param_grid_cv[\"countvectorizer__binary\"] = [True, False]\n",
    "param_grid_cv[\"countvectorizer__analyzer\"] = [\"word\", word_tokenize_stem,\n",
    "                                              word_tokenize_lemma, word_tokenize_lemma_verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search object\n",
    "\n",
    "grid_cv = GridSearchCV(pipe_cv, param_grid_cv, cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "#intialize time stamp\n",
    "t = time()\n",
    "#fit grid search object\n",
    "grid_cv.fit(X, y)\n",
    "#Print time elapsed\n",
    "print (time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best parameters\n",
    "print (grid_cv.best_params_)\n",
    "#Best score\n",
    "print (grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidfvectorizer gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make pipeline for tfidfvectorizer and naive bayes model\n",
    "pipe_tf = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "\n",
    "#Intialize parameters for tfidf vectorizer\n",
    "param_grid_tf = {}\n",
    "param_grid_tf[\"tfidfvectorizer__max_features\"] = [1000, 2500 ,5000, 7500,10000]\n",
    "param_grid_tf[\"tfidfvectorizer__ngram_range\"] = [(1,1), (1,2), (2,2)]\n",
    "param_grid_tf[\"tfidfvectorizer__lowercase\"] = [True, False]\n",
    "param_grid_tf[\"tfidfvectorizer__binary\"] = [True, False]\n",
    "param_grid_tf[\"tfidfvectorizer__analyzer\"] = [\"word\", word_tokenize_stem,\n",
    "                                              word_tokenize_lemma, word_tokenize_lemma_verb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid search object\n",
    "\n",
    "grid_tf = GridSearchCV(pipe_tf, param_grid_tf, cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "#intialize time stamp\n",
    "t = time()\n",
    "#fit grid search object\n",
    "grid_tf.fit(X, y)\n",
    "#Print time elapsed\n",
    "print (time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Countvectorizer randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized grid search with n_iter = 10\n",
    "randsearch_cv = RandomizedSearchCV(pipe_cv, n_iter = 10,\n",
    "                        param_distributions = param_grid_cv, cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "#Time the code \n",
    "\n",
    "t = time()\n",
    "\n",
    "#Fit grid on data\n",
    "randsearch_cv.fit(X, y)\n",
    "\n",
    "#Print time difference\n",
    "\n",
    "print (time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best params\n",
    "print (randsearch_cv.best_params_)\n",
    "#Best score\n",
    "print (randsearch_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tfidfvectorizer randomized search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Randomized grid search with n_iter = 10\n",
    "randsearch_tf = RandomizedSearchCV(pipe_tf, n_iter = 10,\n",
    "                        param_distributions = param_grid_tf, cv = 5, scoring = \"accuracy\")\n",
    "\n",
    "#Time the code \n",
    "\n",
    "t = time()\n",
    "\n",
    "#Fit grid on data\n",
    "randsearch_tf.fit(X, y)\n",
    "\n",
    "#Print time difference\n",
    "\n",
    "print (time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Best params\n",
    "print (randsearch_tf.best_params_)\n",
    "#Best score\n",
    "print (randsearch_tf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This wraps up text classification. Now onto the rest of the lesson."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarizing text\n",
    "\n",
    "We're going to build a very simple summarizer that uses tfidf scores on a corpura of data science and artificial intelligence articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load in data\n",
    "\n",
    "path = \"../../data/NLP_data/ds_articles.csv\"\n",
    "\n",
    "#We're only be using the text and title columns\n",
    "articles = pd.read_csv(path, usecols=[\"text\", \"title\"], encoding=\"utf-8\")\n",
    "\n",
    "#Drop nulls\n",
    "articles.dropna(inplace=True)\n",
    "\n",
    "#Reset index\n",
    "articles.reset_index(inplace=True, drop=True)\n",
    "\n",
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize tfidf with stop_words = english, max_features = 1000, and stem analzyer \n",
    "\n",
    "tfidf = \n",
    "\n",
    "\n",
    "#Fit and transform the text using the tfidf vectorizer\n",
    "text = \n",
    "dtm = \n",
    "\n",
    "#Assign tokens to features\n",
    "features = \n",
    "\n",
    "print (len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dataframe of features and their idf scores\n",
    "idfscores = \n",
    "idfscores[\"tokens\"] = \n",
    "idfscores[\"scores\"] = \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten most imporant words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Top ten least imporant words\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's our summarizer function that will randomly select an article to summarize. By summarize, I mean show the top five words with the highest tfidf values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize():\n",
    "    #Randomly choose index value\n",
    "    index = np.random.choice(articles.index, 1)[0]\n",
    "    article = text.iloc[index]\n",
    "    # create a dictionary of words and their TF-IDF scores\n",
    "    word_scores = {}\n",
    "    for word in TextBlob(article).words:\n",
    "        word = word.lower()\n",
    "        if word in features:\n",
    "            word_scores[word] = dtm[index, features.index(word)]\n",
    "            \n",
    "   # print words with the top 5 TF-IDF scores\n",
    "    print ('TOP SCORING WORDS:')\n",
    "    top_scores = sorted(word_scores.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "    for word, score in top_scores:\n",
    "        print (word)\n",
    "        \n",
    "    #Print title of article\n",
    "    print (\"\\n\", articles.title[index])\n",
    "    \n",
    "    #Print the text of article\n",
    "#     print article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Give it a go\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Similarity with Cosine Similarity and Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "\n",
    "![ew](https://i2.wp.com/dataaspirant.com/wp-content/uploads/2015/04/cosine.png?w=697)\n",
    "<br><br>\n",
    "\" Cosine similarity metric finds the normalized dot product of the two attributes. By determining the cosine similarity, we would effectively try to find the cosine of the angle between the two objects. The cosine of 0° is 1, and it is less than 1 for any other angle.\n",
    "\n",
    "It is thus a judgement of orientation and not magnitude: two vectors with the same orientation have a cosine similarity of 1, two vectors at 90° have a similarity of 0, and two vectors diametrically opposed have a similarity of -1, independent of their magnitude.\n",
    "\n",
    "Cosine similarity is particularly used in positive space, where the outcome is neatly bounded in (0,1). One of the reasons for the popularity of cosine similarity is that it is very efficient to evaluate, especially for sparse vectors.\"\n",
    "<br>\n",
    "Source: [Dataaspirant](http://dataaspirant.com/2015/04/11/five-most-popular-similarity-measures-implementation-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Diy cosine similarity function\n",
    "\n",
    "def square_rooted(x):\n",
    "\n",
    "    return round(np.sqrt(sum([a*a for a in x])),3)\n",
    " \n",
    "def cosine_similarity_function(x,y):\n",
    "\n",
    "    numerator = sum(a*b for a,b in zip(x,y))\n",
    "    denominator = square_rooted(x)*square_rooted(y)\n",
    "    return round(numerator/float(denominator),3)\n",
    " \n",
    "vec1 = [3, 45, 7, 2]\n",
    "vec2 = [2, 54, 13, 15]\n",
    "cosine_similarity_function(vec1, vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Derive matrix of similarities between all the data science articles documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate cosine distance for each pair of documents\n",
    "dist = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make it a dataframe\n",
    "dist_df = \n",
    "\n",
    "#Shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare some articles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Index position of article\n",
    "index = 239"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign titles column to titles variable\n",
    "\n",
    "titles = \n",
    "\n",
    "\n",
    "\n",
    "#Print title\n",
    "print ()\n",
    "\n",
    "#print article\n",
    "\n",
    "print (\"\\n, ************************************************ \\n\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to take the index value and use it grab the column of the scores between every article and the one at index 935"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass\n",
    "dist_column = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get the index values of the 5 \n",
    "\n",
    "closest_index = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass index values into titles and print them\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pass index values into titles and but don't print\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "It is standard practice to cluster with tfidf data instead of the count vectorized data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize clustering algorithm with 4 clusters and fit it on dtm\n",
    "\n",
    "km4 = \n",
    "#Fit algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out silhouette score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign labels to articles dataframe \n",
    "\n",
    "articles[\"cluster\"] = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 5 randomly selected headlines from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think the clusters are? Is it easy decipher? Ignore the silhouette score, does it pass the eye test?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the top words of each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = km4.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = tfidf.get_feature_names()\n",
    "for i in range(4):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print (\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this exercise again but this time we'll cluster the cosine distances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Intialize clustering algorithm with 4 clusters\n",
    "km4 = \n",
    "\n",
    "#fit it on dist array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check out silhouette score\n",
    "silhouette_score(dist, km4.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print 5 randomly selected headlines from each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assign new labels to data frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 0\n",
    "for i in articles[articles.cluster_dist == 0].sample(n=5).title.tolist():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 1\n",
    "for i in articles[articles.cluster_dist == 1].sample(n=5).title.tolist():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 2\n",
    "for i in articles[articles.cluster_dist == 2].sample(n=5).title.tolist():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cluster 3\n",
    "for i in articles[articles.cluster_dist == 3].sample(n=5).title.tolist():\n",
    "    print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are the results better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "\n",
    "My fake news classifer article: https://opendatascience.com/blog/how-to-build-a-fake-news-classification-model/\n",
    "<br>\n",
    "My data science topic modeling article: https://opendatascience.com/blog/how-to-analyze-articles-about-data-science-using-data-science/\n",
    "<br><br>\n",
    "**Regular Expressions**\n",
    "- https://www.dataquest.io/blog/regular-expressions-data-scientists/\n",
    "- https://www.datacamp.com/community/tutorials/python-regular-expression-tutorial\n",
    "- https://www.oreilly.com/ideas/an-introduction-to-regular-expressions\n",
    "\n",
    "\n",
    "**NLP Tutorials**\n",
    "\n",
    "- https://github.com/bonzanini/nlp-tutorial\n",
    "- https://github.com/totalgood/pycon-2016-nlp-tutorial\n",
    "\n",
    "**Text similarity:**\n",
    "- https://janav.wordpress.com/2013/10/27/tf-idf-and-cosine-similarity/\n",
    "- http://blog.christianperone.com/2013/09/machine-learning-cosine-similarity-for-vector-space-models-part-iii/\n",
    "- http://billchambers.me/tutorials/2014/12/22/cosine-similarity-explained-in-python.html\n",
    "- Explains why text similarity uses cosine similarity -> https://www.quora.com/What-are-the-mechanics-of-cosine-similarity-in-natural-language-processing\n",
    "\n",
    "**Text classification:**\n",
    "- Another fake news tutorial - > https://www.datacamp.com/community/tutorials/scikit-learn-fake-news\n",
    "- http://nlpforhackers.io/text-classification/\n",
    "- http://zacstewart.com/2015/04/28/document-classification-with-scikit-learn.html\n",
    "- https://github.com/javedsha/text-classification\n",
    "- https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
    "- https://bbengfort.github.io/tutorials/2016/05/19/text-classification-nltk-sckit-learn.html\n",
    "\n",
    "\n",
    "**Text clustering:**\n",
    "\n",
    "- Great tutorial -> http://brandonrose.org/clustering\n",
    "- http://nlpforhackers.io/recipe-text-clustering/\n",
    "- https://pythonprogramminglanguage.com/kmeans-text-clustering/\n",
    "- http://mccormickml.com/2015/08/05/document-clustering-example-in-scikit-learn/\n",
    "\n",
    "\n",
    "**Word Embeddings/Word2Vec**\n",
    "\n",
    "- https://chatbotsmagazine.com/introduction-to-word-embeddings-55734fd7068a\n",
    "- https://www.springboard.com/blog/introduction-word-embeddings/\n",
    "- http://ruder.io/word-embeddings-1/\n",
    "- https://www.slideshare.net/BhaskarMitra3/a-simple-introduction-to-word-embeddings\n",
    "- https://github.com/fastai/word-embeddings-workshop\n",
    "\n",
    "\n",
    "**Topic Modeling**\n",
    "\n",
    "- http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/\n",
    "- https://blog.bigml.com/2016/11/16/introduction-to-topic-models/\n",
    "- http://nbviewer.jupyter.org/github/ogrisel/notebooks/blob/master/nmf_topics.ipynb?create=1\n",
    "- https://www.youtube.com/watch?v=ZgyA1Q2ywbM\n",
    "- https://www.youtube.com/watch?v=SjRss8Uk6mQ\n",
    "- https://github.com/derekgreene/topic-model-tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab time\n",
    "\n",
    "Pick a text dataset to spend the rest of class working. There are three other datasets in the NLP_data that you can work with: pitchfork album reviews, fake/real news, deadspin, and political lean. Make sure to unzip political lean or fake news. You can also continue to work with the datasets we've already used (data science, yelp, spam.)\n",
    "\n",
    "<br>\n",
    "\n",
    "For the rest of class apply supervised or unsupervised learning techniques to the dataset of your choice. \n",
    "\n",
    "- Build a model that can differentiate between good/bad review, real/fake news, or liberal/conservative leaning or a model that \n",
    "\n",
    "- Predict how many page views a deadspin can get based on its headlines and tags.\n",
    "\n",
    "- Ignore the labels and attempt cluster the articles.\n",
    "\n",
    "- Have fun with the summarizer!!\n",
    "\n",
    "<br>\n",
    "\n",
    "Be prepared to share your results at the end of class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
